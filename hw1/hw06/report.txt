
OS: CentOS Linux release 7.4.1708
Number of Processor Cores: 24

________________________________________________________________
|   Number of Threads   |       Time        |       Speedup     |
________________________________________________________________
|           1           |       12.71       |         1         |
|           4           |       7.28        |        1.75       |
|           8           |       5.2         |        2.44       |
________________________________________________________________


The results shown above show the parallel speedup gained by using a number
of threads over the a single threaded approach. In this example, we see that 
we achieve a maximum speedup of 2.44x over a single threaded appraoch. While this
implementaiton is far from optimal, its performs on par with our previous process 
base implementation. Like our last implementation, the efficency of our speedup
is limited the amount of work that can be done in parallel. In our new implementation,
we are performing system calls to read and write our data to a file serially. Further
we are also performing the data sampling serially, leaving the only the actual 
sort of broken down arrays to be performed in parallel. Since the code running 
in serial still takes a significant amount of time, the amount of speedup we can
gain from the system as a whole is greatly limited (as per Amdahl's law). 

While performance at 8 threads out performed the 8 processes implementation, 
the base program (using 1 thread vs 1 processes) ran slower for the threading 
implementation. This is likely due to the high number of system calls that needed 
to be executed for each of the reading and writing of data. Our improved performance
also can be attributed to the lower overhead cost in establishing multiple threads 
operating on shared memory vs the cost of forking a processes. Finally, in this 
implementation, we ran our benchmark on a syste that had more cores than processes 
running which meant that we were not oversubscribing our cores. Depending on how
intensive the computations are for the code running in parallel, not oversubscribing 
the cores could also have offered a significant increase in performance. 
